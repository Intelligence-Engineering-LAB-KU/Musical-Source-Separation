{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "import IPython.display as ipd\n",
    "import museval as eval4\n",
    "import mir_eval.separation as eval3\n",
    "from time import sleep\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "model_path = 'baseline_model'\n",
    "model_name = 'baseline'\n",
    "\n",
    "musdb_path = '../data/musdb18/preprocessed/'\n",
    "musdb_train_path = musdb_path + 'train/'\n",
    "musdb_valid_path = musdb_path + 'valid/'\n",
    "musdb_test_path = musdb_path + 'test/'\n",
    "\n",
    "\n",
    "mix_name = 'linear_mixture'\n",
    "target_names = ['vocals', 'drums', 'bass', 'other']\n",
    "target_name = target_names[0]\n",
    "\n",
    "dim_c = 4\n",
    "dim_f = 2048\n",
    "dim_t = 128\n",
    "n_fft = 4096\n",
    "hop_length = 1024\n",
    "sampling_rate = 44100\n",
    "chunk_size = n_fft + hop_length * (dim_t-1)\n",
    "trim = 5000  # trim each generated signal piece before concat\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def to_specs(signal):\n",
    "    specs = []\n",
    "    for channel in signal:\n",
    "        spectrogram = librosa.stft(np.array(channel, dtype=np.float32), n_fft=n_fft, center=False, hop_length=hop_length)\n",
    "        specs.append(spectrogram.real)\n",
    "        specs.append(spectrogram.imag)\n",
    "    return np.array(specs)\n",
    "\n",
    "def restore(specs):\n",
    "    specs = np.reshape(specs, (-1, 2, dim_f+1, dim_t))\n",
    "    channels = []\n",
    "    for ri in specs:\n",
    "        signal = librosa.istft(ri[0] + 1.j * ri[1], center=False, hop_length=hop_length)\n",
    "        channels.append(signal)\n",
    "    return np.array(channels)\n",
    "\n",
    "\n",
    "def load(path, s=0.0, d=None):\n",
    "    return librosa.load(path, sr=None, mono=False, offset=s, duration=d)[0]\n",
    "\n",
    "print(chunk_size/sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "musdb_specs = []\n",
    "\n",
    "for i in tqdm_notebook(range(86)):\n",
    "    musdb_specs.append({})\n",
    "    for t in target_names:\n",
    "        musdb_specs[-1][t] = to_specs(load('{0}/{1:02}.wav'.format(musdb_train_path + t, i)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MssDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.size = len(self.data)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        def chunk(specs):\n",
    "            s = np.random.randint(specs.shape[-1] - dim_t)\n",
    "            return specs[:,:,s:s+dim_t]\n",
    "        \n",
    "        target = chunk(self.data[index][target_name])\n",
    "        \n",
    "        # data augmentation (mix instruments from different songs)\n",
    "        mix = target\n",
    "        for t_name in target_names:\n",
    "            if t_name!=target_name:\n",
    "                index2 = np.random.randint(len(self))\n",
    "                target2 = chunk(self.data[index2][t_name])\n",
    "                mix = mix + target2\n",
    "\n",
    "        return torch.tensor(mix), torch.tensor(target) \n",
    "    \n",
    "    \n",
    "train_set = MssDataset(musdb_specs)\n",
    "train_iter = DataLoader(train_set, batch_size=12, shuffle=True)\n",
    "\n",
    "train_set[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_c, l, g, kx, ky):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        \n",
    "        c = in_c\n",
    "        self.H = nn.ModuleList()\n",
    "        for i in range(l):\n",
    "            self.H.append(\n",
    "                nn.Sequential(\n",
    "                    nn.BatchNorm2d(c),\n",
    "                    nn.Conv2d(in_channels=c, out_channels=g, kernel_size=(kx, ky), stride=1, padding=(kx//2, ky//2)),\n",
    "                    nn.ReLU(),\n",
    "                )\n",
    "            )\n",
    "            c += g\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_ = self.H[0](x)\n",
    "        for h in self.H[1:]:\n",
    "            x = torch.cat((x_, x), 1)\n",
    "            x_ = h(x)    \n",
    "               \n",
    "        return x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "    def __init__(self, L, l, g, kx, ky, bn_factor, t_scale):\n",
    "        super(Baseline, self).__init__()\n",
    "        self.n = L//2\n",
    "        \n",
    "        self.first_conv = nn.Sequential(\n",
    "            nn.BatchNorm2d(dim_c),\n",
    "            nn.Conv2d(in_channels=dim_c, out_channels=g, kernel_size=(2,1), stride=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        f = dim_f\n",
    "        self.ds_dense = nn.ModuleList()\n",
    "        self.ds = nn.ModuleList()\n",
    "        for i in range(self.n):\n",
    "            self.ds_dense.append(DenseBlock(g, l, g, kx, ky, f, bn_factor))\n",
    "            \n",
    "            scale = (2,2) if i in t_scale else (1,2)\n",
    "            self.ds.append(\n",
    "                nn.Conv2d(in_channels=g, out_channels=g, kernel_size=scale, stride=scale)\n",
    "            )\n",
    "            f = f//2\n",
    "        \n",
    "        self.mid_dense = DenseBlock(g, l, g, kx, ky, f, bn_factor)\n",
    "        \n",
    "        self.us_dense = nn.ModuleList()\n",
    "        self.us = nn.ModuleList()\n",
    "        for i in range(self.n):\n",
    "            scale = (2,2) if i in self.n-1 - t_scale else (1,2)\n",
    "            self.us.append(\n",
    "                nn.ConvTranspose2d(in_channels=g, out_channels=g, kernel_size=scale, stride=scale)\n",
    "            )\n",
    "            f = f*2\n",
    "            \n",
    "            self.us_dense.append(DenseBlock(2*g, l, g, kx, ky, f, bn_factor))\n",
    "            \n",
    "      \n",
    "        self.final_conv = nn.Conv2d(in_channels=g, out_channels=dim_c, kernel_size=(2,1), stride=1, padding=(1,0))\n",
    "            \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.first_conv(x)\n",
    "        \n",
    "        x = x.transpose(-1,-2)\n",
    "        \n",
    "        ds_outputs = []\n",
    "        for i in range(self.n):\n",
    "            x = self.ds_dense[i](x)\n",
    "            ds_outputs.append(x)\n",
    "            x = self.ds[i](x)\n",
    "        \n",
    "        x = self.mid_dense(x)\n",
    "        \n",
    "        for i in range(self.n):\n",
    "            x = self.us[i](x)\n",
    "            x = torch.cat((x, ds_outputs[-i-1]), 1)\n",
    "            x = self.us_dense[i](x)\n",
    "        \n",
    "        x = x.transpose(-1,-2)\n",
    "        \n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Baseline(L=9, l=5, g=24, fx=3, fy=3, bn_factor=16, t_scale=np.array([1,2,3])).to(device)\n",
    "\n",
    "#model = nn.DataParallel(model, device_ids=[0,1,2]).to(device)\n",
    "\n",
    "loss_trace = []\n",
    "\n",
    "def init_weights(model, ckpt, lr, epoch=None):\n",
    "    if ckpt==0:\n",
    "        print('Start training')\n",
    "        for p in model.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_normal_(p)\n",
    "    else:\n",
    "        global loss_trace\n",
    "        loss_trace = list(np.load('{0}/{1}/{2}_lr{3}_loss.npy'.format(model_path, model_name, target_name, lr)))\n",
    "        if epoch is None:\n",
    "            model.load_state_dict(torch.load('{0}/{1}/{2}_lr{3}.pt'.format(model_path, model_name, target_name, lr)))\n",
    "            optim.load_state_dict(torch.load('{0}/{1}/{2}_lr{3}_optim.pt'.format(model_path, model_name, target_name, lr)))\n",
    "        else:\n",
    "            model.load_state_dict(torch.load('{0}/{1}/{2}_lr{3}_e{4:04}.pt'.format(model_path, model_name, target_name, lr, epoch)))\n",
    "            optim.load_state_dict(torch.load('{0}/{1}/{2}_lr{3}_e{4:04}_optim.pt'.format(model_path, model_name, target_name, lr, epoch)))\n",
    "            loss_trace = loss_trace[:epoch]\n",
    "            \n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "optim = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 80000\n",
    "ckpt_steps = 500\n",
    "ckpt_min_epoch = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_weights(model, 1, lr=lr, epoch=None)\n",
    "\n",
    "\n",
    "save_steps = 5\n",
    "start_e = len(loss_trace) + 1\n",
    "\n",
    "for e in range(start_e, num_epochs):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    for mix, tar in tqdm_notebook(train_iter):\n",
    "        mix = mix.to(device)\n",
    "        tar = tar.to(device)\n",
    "        y_hat = model(mix)\n",
    "        loss = criterion(y_hat, tar)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        loss_sum += loss.item() * mix.shape[0]\n",
    "    \n",
    "    ipd.clear_output(wait=True)\n",
    "    print('epoch' , e)\n",
    "\n",
    "    epoch_avg_loss = loss_sum / len(train_set)\n",
    "    loss_trace.append(epoch_avg_loss)\n",
    "    print(epoch_avg_loss)\n",
    "    plt.plot(loss_trace)\n",
    "    plt.ylim(0, 0.5)\n",
    "    plt.show()\n",
    "    \n",
    "    if e%save_steps==0:\n",
    "        torch.save(optim.state_dict(), '{0}/{1}/{2}_lr{3}_optim.pt'.format(model_path, model_name, target_name, lr))\n",
    "        torch.save(model.state_dict(), '{0}/{1}/{2}_lr{3}.pt'.format(model_path, model_name, target_name, lr))\n",
    "        np.save('{0}/{1}/{2}_lr{3}_loss.npy'.format(model_path, model_name, target_name, lr), loss_trace)\n",
    "    if e>=ckpt_min_epoch and e%ckpt_steps==0:\n",
    "        torch.save(optim.state_dict(), '{0}/{1}/{2}_lr{3}_e{4:04}_optim.pt'.format(model_path, model_name, target_name, lr, e))\n",
    "        torch.save(model.state_dict(), '{0}/{1}/{2}_lr{3}_e{4:04}.pt'.format(model_path, model_name, target_name, lr, e))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_track(y):\n",
    "    n_sample = y.shape[1]\n",
    "    \n",
    "    gen_size = chunk_size-2*trim\n",
    "    pad = gen_size - n_sample%gen_size\n",
    "    y_p = np.concatenate((np.zeros((2,trim)), y, np.zeros((2,pad)), np.zeros((2,trim))), 1)\n",
    "    \n",
    "    all_specs = []\n",
    "    i = 0\n",
    "    while i < n_sample + pad:\n",
    "        specs = to_specs(y_p[:, i:i+chunk_size])\n",
    "        all_specs.append(specs)\n",
    "        i += gen_size\n",
    "\n",
    "    return torch.tensor(all_specs), pad\n",
    "\n",
    "def separate(model, mix_path):\n",
    "    model.eval()\n",
    "    \n",
    "    mix_specs, pad_len = preprocess_track(mix_path)\n",
    "    \n",
    "    # create batches\n",
    "    batch_size = 8\n",
    "    i = 0\n",
    "    num_intervals = mix_specs.shape[0]\n",
    "    batches = []\n",
    "    while i < num_intervals:\n",
    "        batches.append(mix_specs[i:i+batch_size])\n",
    "        i = i + batch_size\n",
    "\n",
    "    # obtain estimated target spectrograms\n",
    "    tar_signal = np.array([[],[]])\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm_notebook(batches):\n",
    "            tar_specs = model(batch.to(device))\n",
    "            for tar_spec in tar_specs:\n",
    "                est_interval = np.array(restore(tar_spec.detach().cpu().numpy()))[:, trim:-trim]\n",
    "                tar_signal = np.concatenate((tar_signal, est_interval), 1)\n",
    "            \n",
    "    return tar_signal[:, :-pad_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_nan(a):\n",
    "    return np.median(a[~np.isnan(a)])\n",
    "\n",
    "def musdb_sdr(ref, est, sr=sampling_rate):\n",
    "    sdr, isr, sir, sar, perm = eval4.metrics.bss_eval(ref, est, window=sr, hop=sr)\n",
    "    return median_nan(sdr[0])\n",
    "\n",
    "def mse(ref, est):\n",
    "    return ((ref-est)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_epoch = 80000\n",
    "min_epoch = 20000\n",
    "cs = 500\n",
    "\n",
    "num_ckpts = (max_epoch - min_epoch) // cs + 1\n",
    "\n",
    "scores_mean = []\n",
    "score_path = '{0}/{1}/lr{2}_valid_{3}.npy'.format(model_path, model_name, lr, target_name)\n",
    "\n",
    "try:\n",
    "    scores_mean = list(np.load(score_path))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "for c in range(num_ckpts):\n",
    "    ckpt_scores = []\n",
    "    init_weights(model, 1, lr=lr, epoch=min_epoch + c*cs)\n",
    "    for i in tqdm_notebook(range(14)):\n",
    "        est = separate(model, load('{0}/{1}/{2:02}.wav'.format(musdb_valid_path, mix_name, i)))\n",
    "        ref = load('{0}/{1}/{2:02}.wav'.format(musdb_valid_path, target_name, i))\n",
    "    \n",
    "        score = mse(ref, est)\n",
    "        print(score)\n",
    "        \n",
    "        ckpt_scores.append(score)\n",
    "    \n",
    "    ckpt_score_mean = np.array(ckpt_scores).mean()\n",
    "    scores_mean.append(ckpt_score_mean)\n",
    "    \n",
    "    ipd.clear_output(wait=True)\n",
    "    print(ckpt_score_mean)\n",
    "    plt.plot(scores_mean)\n",
    "    plt.show()\n",
    "\n",
    "np.save(score_path, np.array(scores_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_weights(model, 1, lr=lr, epoch=49500)\n",
    "\n",
    "for i in tqdm_notebook(range(50)):\n",
    "    track_name = 'test_{0:02}'.format(i)   \n",
    "    tar_signal = separate(model, load('{0}{1}/{2:02}.wav'.format(musdb_test_path, mix_name, i)))\n",
    "    \n",
    "    t_path = '{0}/{1}/estimates_sources/{2}/{3}.wav'.format(model_path, model_name, track_name, target_name)\n",
    "    librosa.output.write_wav(t_path, np.array(tar_signal, np.float32), sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import statistics as stats\n",
    "\n",
    "SDR = []\n",
    "for i in range(50):\n",
    "    \n",
    "    ref = load('{0}/{1}/{2:02}.wav'.format(musdb_test_path, target_name, i))\n",
    "    est = load('{0}/{1}/estimates_sources/test_{2:02}/{3}.wav'.format(model_path, model_name, i, target_name))\n",
    "    sdr = musdb_sdr(np.array([ref.T]), np.array([est.T]))\n",
    "    \n",
    "    SDR.append(sdr)\n",
    "\n",
    "    \n",
    "    ipd.clear_output(wait=True)\n",
    "    print(sdr)\n",
    "    plt.plot(SDR)\n",
    "    plt.show()\n",
    "\n",
    "    print('SDR mean:', stats.mean(SDR))\n",
    "    print('SDR median:', stats.median(SDR))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('{0}/{1}'.format(model_path, model_name))\n",
    "\n",
    "os.mkdir('{0}/{1}/estimates_sources'.format(model_path, model_name))\n",
    "for i in tqdm_notebook(range(50)):\n",
    "    track_name = 'test_{0:02}'.format(i)\n",
    "    p = '{0}/{1}/estimates_sources/test_{2:02}'.format(model_path, model_name, i)\n",
    "    os.mkdir(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
